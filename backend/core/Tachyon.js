
import logger from './logger.js';
import { cerebro } from './cerebro.js';
import { realTimeCortex } from './RealTimeCortex.js';

class Tachyon {
  constructor() {
    this.cache = new Map(); // Stores pre-calculated futures
  }

  async predictAndPreload(currentInput, userHistory) {
    // Only predict if input is substantial
    if (!currentInput || currentInput.length < 5) return;

    // 1. Analyze Pattern & Broadcast Prediction (Ghosting)
    const prompt = `
      USER INPUT: "${currentInput}"
      HISTORY: ${JSON.stringify(userHistory.slice(-3))}
      
      TASK: Predict the SINGLE most likely completion or next command.
      Be aggressive. Guess the user's will.
      
      OUTPUT: Just the predicted text string. No JSON.
    `;

    try {
      // We use a "FAST" model for latency < 200ms
      const prediction = await cerebro.think("FAST", prompt, "You are an Autocomplete Engine.");
      
      if (prediction && prediction.length > currentInput.length) {
          logger.info(`[TACHYON] ðŸ”® Prediction: "${prediction}"`);
          
          // BROADCAST TO FRONTEND (The Ghost Text)
          realTimeCortex.emit('tachyon_prediction', {
              original: currentInput,
              prediction: prediction,
              confidence: 0.85
          });
      }

    } catch (e) {
      // Tachyon failure is silent
    }
  }

  getCachedFuture(intent) {
    if (this.cache.has(intent)) {
      logger.info(`[TACHYON] âš¡ FUTURE COLLAPSED. Serving pre-calculated reality.`);
      const result = this.cache.get(intent);
      this.cache.delete(intent);
      return result;
    }
    return null;
  }
}

export const tachyon = new Tachyon();
